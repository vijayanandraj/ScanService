
Commiting changes from ChatGPT text. This can be a game changer for work.

private boolean doesTableExist(String tableName) {
    String sql = "SHOW TABLES LIKE ?";
    List<String> result = jdbcTemplate.queryForList(sql, new Object[]{tableName}, String.class);
    return !result.isEmpty();
}

private boolean doesTableExist(String tableName) {
    String sql = "SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = ?";
    List<Map<String, Object>> result = jdbcTemplate.queryForList(sql, new Object[]{tableName});
    return !result.isEmpty();
}


if (doesTableExist(tableName)) {
    String truncateTableSQL = "TRUNCATE TABLE " + tableName;
    jdbcTemplate.execute(truncateTableSQL);
} else {
    String createTableSQL = "CREATE TABLE " + tableName + " (" + sqlColumns.toString() + ")";
    jdbcTemplate.execute(createTableSQL);
}


Object value;
if (cell.getCellType() == CellType.NUMERIC) {
    double numericValue = cell.getNumericCellValue();
    if (numericValue == Math.floor(numericValue)) {
        value = (int) numericValue;
    } else {
        value = numericValue;
    }
} else {
    value = cell.toString();
}

columnValues.add("'" + value + "'");


import numpy as np

# Generate some synthetic CPU utilization data as an example
np.random.seed(42)
data_points = np.random.randint(0, 100, 43200)

# Sort the data
sorted_data = np.sort(data_points)

# Calculate the 95th percentile index
index_95th = int((95 / 100) * len(sorted_data))

# Get the 95th percentile value
value_95th = sorted_data[index_95th]


StorageProvider storageProvider = SqlStorageProviderFactory.using(dataSource, null, StorageProviderUtils.DatabaseOptions.SKIP_CREATE);

Vijay, a software craftsman with two decades in the industry, seamlessly combines high-end architecture with hands-on coding passion.
As a seasoned Solution/Application/Technical Architect, he specializes in modernizing applications, building scalable back-end systems, and prioritizing user experience.
A polyglot programmer, he currently specializes in Java and Python, augmented by his adeptness in Cloud technologies and distributed computing.
He's spent 12 years at the bank, taking on diverse roles such as Application, Technical, and Solution Architect across various lines of business.
In his current role, he's the lead architect behind the Modernization Assessment Tool, guiding teams in transitioning from legacy systems to cloud-native architectures.


# Importing pandas and recalculating the target number of cores

import pandas as pd

data = {
    'Server name': ['Server1', 'Server2', 'Server3', 'Server4', 'Server5', 'Server6', 'Server7', 'Server8'],
    'Total Cores': [12, 12, 12, 12, 16, 16, 16, 16],
    'March Utilization': [3.98, 2.98, 1.98, 10.98, 3.71, 4.98, 3.71, 16.07],
    'April Utilization': [4.03, 5.03, 8.03, 45.50, 3.06, 7.50, 3.06, 24.21],
    'May Utilization': [5.67, 8.67, 4.67, 3.67, 2.73, 3.67, 2.73, 23.67],
    'June Utilization': [3.98, 12.98, 11.98, 4.98, 11.53, 4.98, 11.53, 4.98],
    'July Utilization': [10.91, 12.91, 10.91, 2.91, 18.77, 2.91, 18.77, 2.91],
    'August Utilization': [69.1, 0.74, 1.74, 3.28, 27.10, 3.28, 27.10, 33.28]
}

#df = pd.read_excel("/path/to/your/excel/file.xlsx", sheet_name="Sheet1")

df = pd.DataFrame(data)



# Calculate monthly peak core utilization for each server
for month in ['March Utilization', 'April Utilization', 'May Utilization', 'June Utilization', 'July Utilization', 'August Utilization']:
    df[f'{month} Cores'] = df[month] * df['Total Cores']

# Aggregate monthly peaks
monthly_peaks = df[[f'{month} Cores' for month in ['March Utilization', 'April Utilization', 'May Utilization', 'June Utilization', 'July Utilization', 'August Utilization']]].sum()

# Determine overall peak utilization
overall_peak = monthly_peaks.max()

# Consider 20% headroom
headroom = 0.20 * overall_peak

# Calculate total target cores
target_cores = overall_peak + headroom

target_cores

# Compute monthly peaks for each server
monthly_peaks_df = df[[f'{month} Cores' for month in ['March Utilization', 'April Utilization', 'May Utilization', 'June Utilization', 'July Utilization', 'August Utilization']]]

# Compute the median of peaks for each month
median_peaks = monthly_peaks_df.median()

# Anomaly detection using Interquartile Range (IQR)
Q1 = median_peaks.quantile(0.25)
Q3 = median_peaks.quantile(0.75)
IQR = Q3 - Q1

# Define bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out outliers
adjusted_peaks = median_peaks[(median_peaks >= lower_bound) & (median_peaks <= upper_bound)]

# Compute the adjusted peak and add 20% headroom
adjusted_peak = adjusted_peaks.max()
headroom = 0.20 * adjusted_peak
target_cores_adjusted = adjusted_peak + headroom

target_cores_adjusted


@Service
public class EtlService {

    @Autowired
    private JdbcTemplate jdbcTemplate;

    public void startEtlProcess() {
        List<String> allAitIds = getAllAitIds(); // Assume this gets all unique AIT_IDs using native SQL

        List<CompletableFuture<Void>> futures = new ArrayList<>();
        for (String aitId : allAitIds) {
            CompletableFuture<Void> future = processAitId(aitId);
            futures.add(future);
        }

        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
    }

    @Async("taskExecutor")
    public CompletableFuture<Void> processAitId(String aitId) {
        // Fetch records for a specific AIT_ID
        String fetchQuery = "SELECT * FROM source_table WHERE AIT_ID = ?";
        List<Map<String, Object>> fetchedRecords = jdbcTemplate.queryForList(fetchQuery, new Object[]{aitId});

        // Transformation logic
        List<Map<String, Object>> transformedRecords = transform(fetchedRecords); // Implement your own transform method

        // Batch insert into the target table
        String insertQuery = "INSERT INTO target_table (column1, column2, ...) VALUES (?, ?, ...)";
        List<Object[]> batchArgsList = new ArrayList<>();
        for (Map<String, Object> record : transformedRecords) {
            Object[] args = {record.get("column1"), record.get("column2"), /*...*/};
            batchArgsList.add(args);
        }

        jdbcTemplate.batchUpdate(insertQuery, batchArgsList);
        return CompletableFuture.completedFuture(null);
    }

    private List<Map<String, Object>> transform(List<Map<String, Object>> records) {
        // Your transformation logic here
        return records; // Return the transformed records
    }
}
